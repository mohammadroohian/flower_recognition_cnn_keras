{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "\t image count mean: 183\n",
      "\t image count : 915\n",
      "train\n",
      "\t image count mean: 368\n",
      "\t image count : 1840\n",
      "validation\n",
      "\t image count mean: 181\n",
      "\t image count : 905\n",
      "---------------\n",
      "total image count: 3660\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = 'dataset/flowers-recognition_configed'\n",
    "input_data_dir = {'test':None, 'train':None, 'validation':None}\n",
    "\n",
    "totalcounter = 0\n",
    "dfs = {'train':None, 'validation':None, 'test':None}\n",
    "for i in input_data_dir:\n",
    "    print(i)\n",
    "    classes_names = os.listdir(os.path.join(base_dir, i))\n",
    "    input_data_dir[i] = os.path.join(base_dir, i)\n",
    "    classes = {}\n",
    "    for s in classes_names:\n",
    "        classes[s] = len(os.listdir(os.path.join(base_dir, i, s)))\n",
    "        \n",
    "    inputdata = {'flower':None, 'count':None}\n",
    "    inputdata['flower'] = [f for f, c in classes.items()]\n",
    "    inputdata['count'] = [c for f, c in classes.items()]\n",
    "    \n",
    "    dfs[i] = pd.DataFrame(inputdata)\n",
    "    totalcounter += dfs[i]['count'].sum()\n",
    "    print('\\t', 'image count mean:', int(dfs[i]['count'].mean()))\n",
    "    print('\\t', 'image count :', int(dfs[i]['count'].sum()))\n",
    "print('-'.join(['' for i in range(0, 16)]))\n",
    "print('total image count:', totalcounter)    \n",
    "\n",
    "class_count = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "import math\n",
    "\n",
    "h_params = {}\n",
    "\n",
    "# image\n",
    "h_params['image_size'] = 150 # defult 150\n",
    "h_params['batch_size'] = 20 # defult 20\n",
    "\n",
    "# fit\n",
    "h_params['epochs'] = 40\n",
    "h_params['steps_per_epoch'] = math.ceil(dfs['train']['count'].sum()/h_params['batch_size']) # defult 100\n",
    "h_params['validation_steps'] = math.ceil(dfs['validation']['count'].sum()/h_params['batch_size']) # defult 50\n",
    "\n",
    "# compile\n",
    "h_params['learning_rate'] = 1e-4 # defult 2e-5\n",
    "h_params['optimizer'] = optimizers.RMSprop(lr=h_params['learning_rate'])\n",
    "h_params['metrics'] = ['acc']\n",
    "h_params['fine_tuning_startlayer'] = 'block5_conv1' # if None means no fine tuning is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "layer count 19\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=(h_params['image_size'],\n",
    "                             h_params['image_size'],\n",
    "                             3))\n",
    "\n",
    "conv_base.summary()\n",
    "print('layer count', len(conv_base.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,813,381\n",
      "Trainable params: 16,813,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(class_count, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [""]
    }
   ],
   "source": [
    "print('This is the number of trainable weights ''before freezing the conv base:', len(model.trainable_weights))\n",
    "\n",
    "if h_params['fine_tuning_startlayer'] == None:   \n",
    "    conv_base.trainable = False\n",
    "    for i in conv_base.layers:\n",
    "        i.trainable = False\n",
    "else:\n",
    "    conv_base.trainable = True\n",
    "    set_trainable = False\n",
    "    for layer in conv_base.layers:\n",
    "        if layer.name == h_params['fine_tuning_startlayer']:\n",
    "            set_trainable = True\n",
    "        if set_trainable:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "print('This is the number of trainable weights ''after freezing the conv base:', len(model.trainable_weights))    \n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=h_params['optimizer'],\n",
    "                metrics=h_params['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 \t False\n",
      "block1_conv1 \t False\n",
      "block1_conv2 \t False\n",
      "block1_pool \t False\n",
      "block2_conv1 \t False\n",
      "block2_conv2 \t False\n",
      "block2_pool \t False\n",
      "block3_conv1 \t False\n",
      "block3_conv2 \t False\n",
      "block3_conv3 \t False\n",
      "block3_pool \t False\n",
      "block4_conv1 \t False\n",
      "block4_conv2 \t False\n",
      "block4_conv3 \t False\n",
      "block4_pool \t False\n",
      "block5_conv1 \t True\n",
      "block5_conv2 \t True\n",
      "block5_conv3 \t True\n",
      "block5_pool \t True\n"
     ]
    }
   ],
   "source": [
    "for i in conv_base.layers:\n",
    "    print(i.name, '\\t',i.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1840 images belonging to 5 classes.\n",
      "Found 905 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = input_data_dir['train']\n",
    "validation_dir = input_data_dir['validation']\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                #rotation_range=40,\n",
    "                                #width_shift_range=0.2,\n",
    "                                #height_shift_range=0.2,\n",
    "                                #shear_range=0.2,\n",
    "                                #zoom_range=0.2,\n",
    "                                #horizontal_flip=True,\n",
    "                                  )\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(h_params['image_size'], h_params['image_size']),\n",
    "                                                    batch_size=h_params['batch_size'],\n",
    "                                                    class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(h_params['image_size'], h_params['image_size']),\n",
    "                                                        batch_size=h_params['batch_size'],\n",
    "                                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "92/92 [==============================] - 50s 548ms/step - loss: 0.8711 - acc: 0.6712 - val_loss: 0.5715 - val_acc: 0.7945\n",
      "Epoch 2/40\n",
      "92/92 [==============================] - 45s 493ms/step - loss: 0.4273 - acc: 0.8478 - val_loss: 0.4383 - val_acc: 0.8409\n",
      "Epoch 3/40\n",
      "92/92 [==============================] - 46s 495ms/step - loss: 0.2166 - acc: 0.9261 - val_loss: 0.3648 - val_acc: 0.8707\n",
      "Epoch 4/40\n",
      "92/92 [==============================] - 45s 492ms/step - loss: 0.1457 - acc: 0.9582 - val_loss: 0.3680 - val_acc: 0.8818\n",
      "Epoch 5/40\n",
      "92/92 [==============================] - 45s 491ms/step - loss: 0.0700 - acc: 0.9815 - val_loss: 0.4388 - val_acc: 0.8840\n",
      "Epoch 6/40\n",
      "92/92 [==============================] - 45s 491ms/step - loss: 0.0653 - acc: 0.9826 - val_loss: 0.4065 - val_acc: 0.8928\n",
      "Epoch 7/40\n",
      "92/92 [==============================] - 45s 491ms/step - loss: 0.0486 - acc: 0.9864 - val_loss: 0.5087 - val_acc: 0.8961\n",
      "Epoch 8/40\n",
      "92/92 [==============================] - 45s 492ms/step - loss: 0.0527 - acc: 0.9870 - val_loss: 0.4391 - val_acc: 0.8983\n",
      "Epoch 9/40\n",
      "92/92 [==============================] - 45s 491ms/step - loss: 0.0254 - acc: 0.9951 - val_loss: 0.6075 - val_acc: 0.8972\n",
      "Epoch 10/40\n",
      "92/92 [==============================] - 45s 492ms/step - loss: 0.0487 - acc: 0.9891 - val_loss: 0.5424 - val_acc: 0.8972\n",
      "Epoch 11/40\n",
      "92/92 [==============================] - 45s 491ms/step - loss: 0.0311 - acc: 0.9957 - val_loss: 0.5531 - val_acc: 0.8972\n",
      "Epoch 12/40\n",
      "92/92 [==============================] - 45s 492ms/step - loss: 0.1131 - acc: 0.9826 - val_loss: 0.4090 - val_acc: 0.8972\n",
      "Epoch 13/40\n",
      "92/92 [==============================] - 45s 491ms/step - loss: 0.0450 - acc: 0.9929 - val_loss: 0.4714 - val_acc: 0.8939\n",
      "Epoch 14/40\n",
      "92/92 [==============================] - 45s 491ms/step - loss: 0.0405 - acc: 0.9957 - val_loss: 0.6811 - val_acc: 0.8773\n",
      "Epoch 15/40\n",
      "92/92 [==============================] - 45s 492ms/step - loss: 0.0656 - acc: 0.9918 - val_loss: 0.5184 - val_acc: 0.8674\n",
      "Epoch 16/40\n",
      "92/92 [==============================] - 45s 492ms/step - loss: 0.0566 - acc: 0.9891 - val_loss: 0.5625 - val_acc: 0.8773\n",
      "Epoch 17/40\n",
      "92/92 [==============================] - 45s 492ms/step - loss: 0.0475 - acc: 0.9918 - val_loss: 0.5996 - val_acc: 0.8972\n",
      "Epoch 18/40\n",
      "92/92 [==============================] - 45s 492ms/step - loss: 0.0513 - acc: 0.9924 - val_loss: 0.9066 - val_acc: 0.8762\n",
      "Epoch 19/40\n",
      "92/92 [==============================] - 45s 490ms/step - loss: 0.0292 - acc: 0.9935 - val_loss: 0.7180 - val_acc: 0.8884\n",
      "Epoch 20/40\n",
      "92/92 [==============================] - 45s 490ms/step - loss: 0.0711 - acc: 0.9864 - val_loss: 0.5698 - val_acc: 0.8829\n",
      "Epoch 21/40\n",
      "92/92 [==============================] - 45s 490ms/step - loss: 0.0363 - acc: 0.9908 - val_loss: 0.5952 - val_acc: 0.8917\n",
      "Epoch 22/40\n",
      "92/92 [==============================] - 45s 490ms/step - loss: 0.0287 - acc: 0.9957 - val_loss: 0.7924 - val_acc: 0.8829\n",
      "Epoch 23/40\n",
      "92/92 [==============================] - 45s 489ms/step - loss: 0.0066 - acc: 0.9973 - val_loss: 0.8789 - val_acc: 0.9028\n",
      "Epoch 24/40\n",
      "92/92 [==============================] - 45s 490ms/step - loss: 0.0502 - acc: 0.9908 - val_loss: 0.7880 - val_acc: 0.8873\n",
      "Epoch 25/40\n",
      "92/92 [==============================] - 45s 490ms/step - loss: 0.0529 - acc: 0.9897 - val_loss: 0.9145 - val_acc: 0.8884\n",
      "Epoch 26/40\n",
      "92/92 [==============================] - 45s 489ms/step - loss: 0.0165 - acc: 0.9973 - val_loss: 0.7311 - val_acc: 0.8917\n",
      "Epoch 27/40\n",
      "92/92 [==============================] - 45s 490ms/step - loss: 0.0348 - acc: 0.9946 - val_loss: 0.7487 - val_acc: 0.8796\n",
      "Epoch 28/40\n",
      "92/92 [==============================] - 45s 492ms/step - loss: 0.0133 - acc: 0.9978 - val_loss: 1.1489 - val_acc: 0.8917\n",
      "Epoch 29/40\n",
      "92/92 [==============================] - 45s 494ms/step - loss: 0.0955 - acc: 0.9897 - val_loss: 0.7294 - val_acc: 0.8983\n",
      "Epoch 30/40\n",
      "92/92 [==============================] - 45s 493ms/step - loss: 7.6670e-06 - acc: 1.0000 - val_loss: 0.9256 - val_acc: 0.8950\n",
      "Epoch 31/40\n",
      "92/92 [==============================] - 45s 491ms/step - loss: 0.0582 - acc: 0.9946 - val_loss: 1.0393 - val_acc: 0.8718\n",
      "Epoch 32/40\n",
      "92/92 [==============================] - 45s 491ms/step - loss: 0.0534 - acc: 0.9935 - val_loss: 1.0989 - val_acc: 0.8773\n",
      "Epoch 33/40\n",
      "92/92 [==============================] - 45s 492ms/step - loss: 0.0870 - acc: 0.9908 - val_loss: 0.8542 - val_acc: 0.8796\n",
      "Epoch 34/40\n",
      "92/92 [==============================] - 45s 493ms/step - loss: 0.0359 - acc: 0.9908 - val_loss: 0.8923 - val_acc: 0.8818\n",
      "Epoch 35/40\n",
      "92/92 [==============================] - 45s 495ms/step - loss: 0.0335 - acc: 0.9940 - val_loss: 1.1643 - val_acc: 0.8729\n",
      "Epoch 36/40\n",
      "92/92 [==============================] - 45s 494ms/step - loss: 0.0569 - acc: 0.9913 - val_loss: 0.9329 - val_acc: 0.8873\n",
      "Epoch 37/40\n",
      "92/92 [==============================] - 45s 493ms/step - loss: 0.0386 - acc: 0.9935 - val_loss: 1.6441 - val_acc: 0.8475\n",
      "Epoch 38/40\n",
      "92/92 [==============================] - 46s 495ms/step - loss: 0.0328 - acc: 0.9935 - val_loss: 1.2409 - val_acc: 0.8652\n",
      "Epoch 39/40\n",
      "92/92 [==============================] - 45s 493ms/step - loss: 0.0932 - acc: 0.9826 - val_loss: 1.1914 - val_acc: 0.8807\n",
      "Epoch 40/40\n",
      "92/92 [==============================] - 45s 494ms/step - loss: 0.0211 - acc: 0.9962 - val_loss: 1.0096 - val_acc: 0.8851\n"
     ]
    }
   ],
   "source": [
    "#### from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "startt = time.time()\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=h_params['steps_per_epoch'],\n",
    "                              epochs=h_params['epochs'],\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=h_params['validation_steps'])\n",
    "\n",
    "# save model\n",
    "import helper as hlp\n",
    "model_h = {}\n",
    "model_h['history'] = history\n",
    "model_h['train_duration'] = round(time.time() - startt)\n",
    "model_h['hyper_parameters'] = h_params\n",
    "model_h['hyper_parameters']['optimizer'] = str(h_params['optimizer'])\n",
    "filename = str(round(time.time()))\n",
    "filename = '_'.join([filename[:5], filename[5:6], filename[6:7], filename[7:8], filename[8:], 'pretrained_vgg16_embeded'])\n",
    "hlp.save(model_h, 'models/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show result with plot\n",
    "print('model file name is:', filename)\n",
    "hlp.show_model_plot(model_h);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "92/92 [==============================] - 51s 550ms/step - loss: 0.8692 - acc: 0.6620 - val_loss: 0.6797 - val_acc: 0.7392\n",
      "Epoch 2/9\n",
      "92/92 [==============================] - 46s 497ms/step - loss: 0.4188 - acc: 0.8435 - val_loss: 0.4361 - val_acc: 0.8365\n",
      "Epoch 3/9\n",
      "92/92 [==============================] - 46s 496ms/step - loss: 0.2353 - acc: 0.9223 - val_loss: 0.3646 - val_acc: 0.8807\n",
      "Epoch 4/9\n",
      "92/92 [==============================] - 46s 496ms/step - loss: 0.1274 - acc: 0.9592 - val_loss: 0.4256 - val_acc: 0.8950\n",
      "Epoch 5/9\n",
      "92/92 [==============================] - 46s 496ms/step - loss: 0.0933 - acc: 0.9728 - val_loss: 0.3624 - val_acc: 0.8851\n",
      "Epoch 6/9\n",
      "92/92 [==============================] - 46s 496ms/step - loss: 0.0474 - acc: 0.9870 - val_loss: 0.3386 - val_acc: 0.8829\n",
      "Epoch 7/9\n",
      "92/92 [==============================] - 46s 495ms/step - loss: 0.0596 - acc: 0.9842 - val_loss: 0.4592 - val_acc: 0.8917\n",
      "Epoch 8/9\n",
      "92/92 [==============================] - 45s 494ms/step - loss: 0.0397 - acc: 0.9924 - val_loss: 0.4129 - val_acc: 0.9083\n",
      "Epoch 9/9\n",
      "92/92 [==============================] - 45s 494ms/step - loss: 0.0504 - acc: 0.9880 - val_loss: 0.6051 - val_acc: 0.8983\n"
     ]
    }
   ],
   "source": [
    "#### from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "startt = time.time()\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=h_params['steps_per_epoch'],\n",
    "                              epochs=9,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=h_params['validation_steps'])\n",
    "\n",
    "# save model\n",
    "import helper as hlp\n",
    "model_h = {}\n",
    "model_h['history'] = history\n",
    "model_h['train_duration'] = round(time.time() - startt)\n",
    "model_h['hyper_parameters'] = h_params\n",
    "model_h['hyper_parameters']['optimizer'] = str(h_params['optimizer'])\n",
    "filename = str(round(time.time()))\n",
    "filename = '_'.join([filename[:5], filename[5:6], filename[6:7], filename[7:8], filename[8:], 'pretrained_vgg16_embeded_bestmodel'])\n",
    "hlp.save(model_h, 'models/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}